{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9807db",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m執行具有 'Python 3.12.5' 的儲存格需要 ipykernel 套件。\n",
      "\u001b[1;31m執行下列命令以將 'ipykernel' 安裝到 Python 環境中。\n",
      "\u001b[1;31m命令: 'c:/Users/User/AppData/Local/Programs/Python/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "from flask import Flask, render_template\n",
    "from flask_socketio import SocketIO, emit\n",
    "import base64\n",
    "\n",
    "# Flask and SocketIO setup\n",
    "app = Flask(__name__)\n",
    "socketio = SocketIO(app)\n",
    "\n",
    "# Set up folders for collections\n",
    "DATA_PATH = os.path.join('Warn_Data')\n",
    "warnings = np.array(['lift your head up & keep your back straight',\n",
    "                     'lift your feet higher',\n",
    "                     'lower your feet',\n",
    "                     'swing your arms more',\n",
    "                     'reduce armswing'])\n",
    "no_sequences = 30\n",
    "sequence_length = 30\n",
    "\n",
    "# Create label map\n",
    "label_map = {label: num for num, label in enumerate(warnings)}\n",
    "\n",
    "# Load in the pre-trained model\n",
    "try:\n",
    "    model = load_model('C:/Users/User/Desktop/run_project/SlowJogging_model.keras')  # Adjust path if necessary\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Initialize mediapipe models for pose, face, hand detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "# Function to calculate angle between 3 points\n",
    "def calculate_angle(a, b, c):\n",
    "    a, b, c = np.array(a), np.array(b), np.array(c)\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "    return angle\n",
    "\n",
    "# Function to process incoming video frame using Mediapipe and model\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results\n",
    "\n",
    "# Function to extract keypoints from the Mediapipe results\n",
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(132)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(1404)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, lh, rh])\n",
    "\n",
    "# Function to update the footstep counter\n",
    "left_knee_up = False\n",
    "right_knee_up = False\n",
    "step_count = 0\n",
    "knee_angle_threshold = 160\n",
    "\n",
    "def update_footstep_counter(results):\n",
    "    global step_count, left_knee_up, right_knee_up, knee_angle_threshold\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "        left_hip = [landmarks[mp_holistic.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_holistic.PoseLandmark.LEFT_HIP.value].y]\n",
    "        left_knee = [landmarks[mp_holistic.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp_holistic.PoseLandmark.LEFT_KNEE.value].y]\n",
    "        left_ankle = [landmarks[mp_holistic.PoseLandmark.LEFT_ANKLE.value].x, landmarks[mp_holistic.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "\n",
    "        right_hip = [landmarks[mp_holistic.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp_holistic.PoseLandmark.RIGHT_HIP.value].y]\n",
    "        right_knee = [landmarks[mp_holistic.PoseLandmark.RIGHT_KNEE.value].x, landmarks[mp_holistic.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "        right_ankle = [landmarks[mp_holistic.PoseLandmark.RIGHT_ANKLE.value].x, landmarks[mp_holistic.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "\n",
    "        left_knee_angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "        right_knee_angle = calculate_angle(right_hip, right_knee, right_ankle)\n",
    "\n",
    "        if left_knee_angle < knee_angle_threshold and not left_knee_up:\n",
    "            left_knee_up = True\n",
    "        if left_knee_angle >= knee_angle_threshold and left_knee_up:\n",
    "            left_knee_up = False\n",
    "            step_count += 1\n",
    "\n",
    "        if right_knee_angle < knee_angle_threshold and not right_knee_up:\n",
    "            right_knee_up = True\n",
    "        if right_knee_angle >= knee_angle_threshold and right_knee_up:\n",
    "            right_knee_up = False\n",
    "            step_count += 1\n",
    "\n",
    "    return step_count\n",
    "\n",
    "# Flask SocketIO route to handle incoming video frames\n",
    "@socketio.on('video_frame')\n",
    "def handle_video_frame(data):\n",
    "    # Decode base64 image data\n",
    "    frame_data = base64.b64decode(data.split(',')[1])\n",
    "    np_data = np.frombuffer(frame_data, np.uint8)\n",
    "    frame = cv2.imdecode(np_data, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Process the frame with Mediapipe\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "\n",
    "        # Extract keypoints and make predictions\n",
    "        if results.pose_landmarks:\n",
    "            keypoints = extract_keypoints(results)\n",
    "            sequence = [keypoints]\n",
    "            if len(sequence) == 30:\n",
    "                res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "                index = np.argmax(res)\n",
    "                warning = warnings[index] if res[index] > 0.5 else None\n",
    "\n",
    "                # Count steps\n",
    "                steps = update_footstep_counter(results)\n",
    "\n",
    "                # Send results back to the client\n",
    "                emit('prediction_result', {'warning': warning, 'steps': steps})\n",
    "\n",
    "# Serve the front-end\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('run120.html')\n",
    "\n",
    "# Run Flask server\n",
    "if __name__ == '__main__':\n",
    "    socketio.run(app, host='0.0.0.0', port=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c29ce3e-1b28-4d82-bd17-1494cf169e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
